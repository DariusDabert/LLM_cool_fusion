{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# the cool_fusion function are in source/cool_fusion.py\n",
    "from source.cool_fusion import CoolFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"your key here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariusdabert/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/dariusdabert/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Define the model names\n",
    "model_name1 = \"gpt2\"\n",
    "model_name2 = \"EleutherAI/gpt-neo-125M\"\n",
    "\n",
    "# Load tokenizers\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_name1)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name2)\n",
    "\n",
    "# Load models (using CPU by default; add device_map=\"auto\" for GPU)\n",
    "model1 = AutoModelForCausalLM.from_pretrained(model_name1)\n",
    "model2 = AutoModelForCausalLM.from_pretrained(model_name2)\n",
    "\n",
    "# Sample prompt for generation\n",
    "prompt = \"Once upon a time\"\n",
    "\n",
    "# Prepare inputs\n",
    "input_ids1 = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids2 = tokenizer2(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate text with both models\n",
    "output1 = model1.generate(input_ids1, max_new_tokens=50, do_sample=True)\n",
    "output2 = model2.generate(input_ids2, max_new_tokens=50, do_sample=True)\n",
    "\n",
    "# Decode and print outputs\n",
    "print(\"GPT-2 Output:\")\n",
    "print(tokenizer1.decode(output1[0], skip_special_tokens=True))\n",
    "print(\"\\nGPT-Neo Output:\")\n",
    "print(tokenizer2.decode(output2[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (PPL: 15.99): , the concept of a “real” state was still an exciting proposition. “What about what we’ve been doing for a long time?” asked the head of the state’s commission this week. “We’ve been doing our jobs since before we were born.” “I’m the person who created the current government,” said Richard Evans, who served four years in the governor’s office with Republican governors and was reemployed as president of the Federal Reserve last year as governor. “There’s a real responsibility that there’s been for more than 75 years today for which we have not been responsible.” On June 11, 2009, state police broke into the home of a 19-year-old girl, allegedly from a drug-related accident near the North Bridge Station, and seized her. (The victim, known as “Dana,” fled the scene of the crime.) The girl died shortly after her body was released. Evans was a political activist who had called the girl “a woman from the right, but from the left.” He was in the\n",
      "Rank 2 (PPL: 18.37): , we saw that the most interesting players in StarCraft2, the ones I would consider a team, are those that play in an SC2 tournament at the national level or where it makes sense to get involved in LAN events and to train with some of the best Koreans. My team was in the top 8 in Korea and my brother and I took our teams to North America and a few countries after my return to Korea. It took us four years to make it to Japan and one year to Taiwan, but we won at least five of them in less than a month. It isn't really a surprise that the top 1% of StarCraft players in a small number of tournaments, like I did, have made the leap to the highest level. But what is not surprising is that many of these players get into SC2 tournaments through playing against each other, a great trait for Korean StarCraft that I hadn't noticed. For all of my thoughts about my teammate and team, I am very proud and optimistic that my teammates can continue their efforts with the same passion I have so far. I'm grateful for the time we spent together throughout the years leading StarCraft to this level and how supportive I was from the start. I hope to see\n"
     ]
    }
   ],
   "source": [
    "# usage\n",
    "\n",
    "fused_model = CoolFusion(\n",
    "    models={\"gpt2\": model1, \"EleutherAI/gpt-neo-125M\": model2},\n",
    "    tokenizers={\"gpt2\": tokenizer1, \"EleutherAI/gpt-neo-125M\": tokenizer2},\n",
    "    max_length=250\n",
    ")\n",
    "\n",
    "context = \"Once upon a time\"\n",
    "candidates = fused_model.generate(context)\n",
    "for i, (text, ppl) in enumerate(candidates):\n",
    "    print(f\"Rank {i + 1} (PPL: {ppl:.2f}): {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
